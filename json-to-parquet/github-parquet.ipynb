{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coiled for ETL #1\n",
    "# Process 75GB of JSON Data into Parquet in under 10 minutes\n",
    "\n",
    "The *Coiled for ETL* series demonstrates how Coiled can speed up your existing ETL workflows for larger-than-memory datasets.\n",
    "\n",
    "This edition presents a common ETL use case in which you will: \n",
    "- **Extract** raw .json data scraped from the web, \n",
    "- **Transform** it into tabular DataFrame format optimal for EDA and/or ML,\n",
    "- **Load** it to a cloud object storage as parquet for future reference.\n",
    "\n",
    "> If you're not familiar with Parquet and its benefits over other formats like .json and .csv, check out [this blog](https://coiled.io/blog/parquet-column-pruning-predicate-pushdown/) \n",
    "\n",
    "We’ll be working with data from the [Github Archive project](https://www.gharchive.org/) for the year 2015. This dataset logs all public activity on Github and takes up ~75GB in uncompressed form. That means you most likely can’t process it entirely on your local machine. \n",
    "\n",
    "Upon completing this notebook, you will be able to:\n",
    "1. Build and test your ETL workflow locally first, using a single test file representing 1 hour of GH activity data\n",
    "2. Scale that same workflow out to the cloud using Dask and Coiled to process the entire dataset\n",
    "\n",
    "*Spoiler alert*: you’ll be running the exact same code in both cases, just changing the place where the computations are run.\n",
    "\n",
    "### TO DO\n",
    "1. Mention: Use environment.yml in repo locally\n",
    "2. Remove path to public S3 bucket in final version? Check with Samantha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your ETL Pipeline Locally\n",
    "\n",
    "Before applying any kind of transformation to a dataset, you'll likely first want to get a sense for what it contains and the kinds of data wrangling you might have to do. That's why we'll build our ETL pipeline locally first by:\n",
    "\n",
    "1. Extracting the data\n",
    "2. Transforming it into a DataFrame\n",
    "3. Loading it to a local directory in Parquet file format\n",
    "\n",
    "### 1. Extract the Data\n",
    "We'll start by inspecting a single file from the Github Archive. This represents 1 hour of data and takes up ~5MB of data. There's no need to work with any kind of parallel or cloud computing here, so you can iterate locally for now.\n",
    "\n",
    "> *Only scale out to the cloud if and when necessary to avoid unnecessary costs and code complexity.*\n",
    "\n",
    "The Github Archive data can be accessed via URLs.  Let’s **wget** a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-07 10:38:55--  https://data.gharchive.org/2015-01-01-15.json.gz\n",
      "Resolving data.gharchive.org (data.gharchive.org)... 172.67.168.206, 104.21.46.175\n",
      "Connecting to data.gharchive.org (data.gharchive.org)|172.67.168.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3844072 (3.7M) [application/gzip]\n",
      "Saving to: '2015-01-01-15.json.gz.6'\n",
      "\n",
      "2015-01-01-15.json. 100%[===================>]   3.67M  15.0MB/s    in 0.2s    \n",
      "\n",
      "2021-09-07 10:38:55 (15.0 MB/s) - '2015-01-01-15.json.gz.6' saved [3844072/3844072]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.gharchive.org/2015-01-01-15.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in gzipped .json format. Let's start by loading it into a Dask Bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "import ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': '2489651045',\n",
       "  'type': 'CreateEvent',\n",
       "  'actor': {'id': 665991,\n",
       "   'login': 'petroav',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/petroav',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/665991?'},\n",
       "  'repo': {'id': 28688495,\n",
       "   'name': 'petroav/6.828',\n",
       "   'url': 'https://api.github.com/repos/petroav/6.828'},\n",
       "  'payload': {'ref': 'master',\n",
       "   'ref_type': 'branch',\n",
       "   'master_branch': 'master',\n",
       "   'description': \"Solution to homework and assignments from MIT's 6.828 (Operating Systems Engineering). Done in my spare time.\",\n",
       "   'pusher_type': 'user'},\n",
       "  'public': True,\n",
       "  'created_at': '2015-01-01T15:00:00Z'},)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test data into dask bag and inspect first entry\n",
    "records = db.read_text(\"2015-01-01-15.json.gz\").map(ujson.loads)\n",
    "records.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform into DataFrame\n",
    "\n",
    "\n",
    "#### Subsetting the data\n",
    "\n",
    "There are several different schemas overlapping here, which means we can't simply cast this into a pandas or Dask DataFrame. We **can** filter out one subset, though, and work with that. \n",
    "\n",
    "Let's take a look at the frequencies of the different **types** of records in this test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CreateEvent', 1471),\n",
       " ('PushEvent', 5815),\n",
       " ('WatchEvent', 1230),\n",
       " ('ReleaseEvent', 60),\n",
       " ('PullRequestEvent', 474),\n",
       " ('IssuesEvent', 545),\n",
       " ('ForkEvent', 355),\n",
       " ('GollumEvent', 61),\n",
       " ('IssueCommentEvent', 844),\n",
       " ('DeleteEvent', 260),\n",
       " ('PullRequestReviewCommentEvent', 136),\n",
       " ('CommitCommentEvent', 73),\n",
       " ('MemberEvent', 25),\n",
       " ('PublicEvent', 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.pluck(\"type\").frequencies().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PushEvents seem popular, and also include interesting information. Let's start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': '2489651051',\n",
       "  'type': 'PushEvent',\n",
       "  'actor': {'id': 3854017,\n",
       "   'login': 'rspt',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/rspt',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/3854017?'},\n",
       "  'repo': {'id': 28671719,\n",
       "   'name': 'rspt/rspt-theme',\n",
       "   'url': 'https://api.github.com/repos/rspt/rspt-theme'},\n",
       "  'payload': {'push_id': 536863970,\n",
       "   'size': 1,\n",
       "   'distinct_size': 1,\n",
       "   'ref': 'refs/heads/master',\n",
       "   'head': '6b089eb4a43f728f0a594388092f480f2ecacfcd',\n",
       "   'before': '437c03652caa0bc4a7554b18d5c0a394c2f3d326',\n",
       "   'commits': [{'sha': '6b089eb4a43f728f0a594388092f480f2ecacfcd',\n",
       "     'author': {'email': '5c682c2d1ec4073e277f9ba9f4bdf07e5794dabe@rspt.ch',\n",
       "      'name': 'rspt'},\n",
       "     'message': 'Fix main header height on mobile',\n",
       "     'distinct': True,\n",
       "     'url': 'https://api.github.com/repos/rspt/rspt-theme/commits/6b089eb4a43f728f0a594388092f480f2ecacfcd'}]},\n",
       "  'public': True,\n",
       "  'created_at': '2015-01-01T15:00:01Z'},)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.filter(lambda record: record[\"type\"] == \"PushEvent\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening the data\n",
    "\n",
    "Recall that we want to get this data into a format that makes sense for EDA (Exploratory Data Analysis) and ML, which means we'll need to get it into a pandas or Dask DataFrame. To do that, we'll have to flatten down this data so that pandas operations can be applied to it. While we're at it, let's also filter out some of the attributes so that we're only working with the data we really care about.\n",
    "\n",
    "The function below extracts information about the commits in each PushEvent. This flattens out the nested data into a tabular format where each row represents a single commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that extracts relevant data\n",
    "def process(record):\n",
    "    try:\n",
    "        for commit in record[\"payload\"][\"commits\"]:\n",
    "            yield {\n",
    "                \"user\": record[\"actor\"][\"login\"],\n",
    "                \"repo\": record[\"repo\"][\"name\"],\n",
    "                \"created_at\": record[\"created_at\"],\n",
    "                \"message\": commit[\"message\"],\n",
    "                \"author\": commit[\"author\"][\"name\"],\n",
    "            }\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that function on a single record to confirm it's working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user': 'rspt',\n",
       "  'repo': 'rspt/rspt-theme',\n",
       "  'created_at': '2015-01-01T15:00:01Z',\n",
       "  'message': 'Fix main header height on mobile',\n",
       "  'author': 'rspt'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply processing function to 1 record\n",
    "[record] = records.filter(lambda record: record[\"type\"] == \"PushEvent\").take(1)\n",
    "list(process(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply this to all the PushEvent records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'user': 'soumith',\n",
       "  'repo': 'soumith/fbcunn',\n",
       "  'created_at': '2015-01-01T01:00:00Z',\n",
       "  'message': 'back to old structure, except lua files moved out',\n",
       "  'author': 'Soumith Chintala'},\n",
       " {'user': 'soumith',\n",
       "  'repo': 'soumith/fbcunn',\n",
       "  'created_at': '2015-01-01T01:00:00Z',\n",
       "  'message': '...',\n",
       "  'author': 'Soumith Chintala'},\n",
       " {'user': 'soumith',\n",
       "  'repo': 'soumith/fbcunn',\n",
       "  'created_at': '2015-01-01T01:00:00Z',\n",
       "  'message': '...',\n",
       "  'author': 'Soumith Chintala'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply processing function to all records in test file\n",
    "flattened = records.filter(lambda record: record[\"type\"] == \"PushEvent\").map(process).flatten()\n",
    "flattened.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Dataframe\n",
    "We're now ready to convert this flattened data into a DataFrame. We'll convert straight into a Dask DataFrame since we're already working with a Dask Bag and will be applying more Dask operations later in this notebook. Depending on your workflow, you could also work with pandas DataFrames here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>repo</th>\n",
       "      <th>created_at</th>\n",
       "      <th>message</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soumith</td>\n",
       "      <td>soumith/fbcunn</td>\n",
       "      <td>2015-01-01T01:00:00Z</td>\n",
       "      <td>back to old structure, except lua files moved out</td>\n",
       "      <td>Soumith Chintala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soumith</td>\n",
       "      <td>soumith/fbcunn</td>\n",
       "      <td>2015-01-01T01:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Soumith Chintala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soumith</td>\n",
       "      <td>soumith/fbcunn</td>\n",
       "      <td>2015-01-01T01:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Soumith Chintala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soumith</td>\n",
       "      <td>soumith/fbcunn</td>\n",
       "      <td>2015-01-01T01:00:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Soumith Chintala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radix</td>\n",
       "      <td>radix/effect</td>\n",
       "      <td>2015-01-01T01:00:00Z</td>\n",
       "      <td>put the auto-generated API docs in the reposit...</td>\n",
       "      <td>Christopher Armstrong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user            repo            created_at  \\\n",
       "0  soumith  soumith/fbcunn  2015-01-01T01:00:00Z   \n",
       "1  soumith  soumith/fbcunn  2015-01-01T01:00:00Z   \n",
       "2  soumith  soumith/fbcunn  2015-01-01T01:00:00Z   \n",
       "3  soumith  soumith/fbcunn  2015-01-01T01:00:00Z   \n",
       "4    radix    radix/effect  2015-01-01T01:00:00Z   \n",
       "\n",
       "                                             message                 author  \n",
       "0  back to old structure, except lua files moved out       Soumith Chintala  \n",
       "1                                                ...       Soumith Chintala  \n",
       "2                                                ...       Soumith Chintala  \n",
       "3                                                ...       Soumith Chintala  \n",
       "4  put the auto-generated API docs in the reposit...  Christopher Armstrong  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast flattened json data into dataframe\n",
    "df = flattened.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, we've managed to convert the .json test file into a Dask DataFrame. \n",
    "\n",
    "Note that the DataFrame contains just over 10k entries. This is because we've flattened the nested PushEvents into single commits and apparently some of the 5815 PushEvents in **records** contained multiple commits each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load to Disk as Parquet\n",
    "\n",
    "We're now ready to write our DataFrame into a .parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write test dataframe to local directory as parquet\n",
    "df.to_parquet(\n",
    "    \"test.parq\", \n",
    "    engine=\"pyarrow\",\n",
    "    compression=\"snappy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final sanity-check, let's import the saved parquet file as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>repo</th>\n",
       "      <th>created_at</th>\n",
       "      <th>message</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rspt</td>\n",
       "      <td>rspt/rspt-theme</td>\n",
       "      <td>2015-01-01T15:00:01Z</td>\n",
       "      <td>Fix main header height on mobile</td>\n",
       "      <td>rspt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>izuzero</td>\n",
       "      <td>izuzero/xe-module-ajaxboard</td>\n",
       "      <td>2015-01-01T15:00:01Z</td>\n",
       "      <td>#20 게시글 및 댓글 삭제 시 새로고침이 되는 문제 해결\\n\\n원래 의도는 새로고...</td>\n",
       "      <td>Eunsoo Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>winterbe</td>\n",
       "      <td>winterbe/streamjs</td>\n",
       "      <td>2015-01-01T15:00:03Z</td>\n",
       "      <td>Add comparator support for min, max operations</td>\n",
       "      <td>Benjamin Winterberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hermanwahyudi</td>\n",
       "      <td>hermanwahyudi/selenium</td>\n",
       "      <td>2015-01-01T15:00:03Z</td>\n",
       "      <td>Update README.md</td>\n",
       "      <td>Herman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jdilt</td>\n",
       "      <td>jdilt/jdilt.github.io</td>\n",
       "      <td>2015-01-01T15:00:03Z</td>\n",
       "      <td>refine index page and about page</td>\n",
       "      <td>jdilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                         repo            created_at  \\\n",
       "0           rspt              rspt/rspt-theme  2015-01-01T15:00:01Z   \n",
       "1        izuzero  izuzero/xe-module-ajaxboard  2015-01-01T15:00:01Z   \n",
       "2       winterbe            winterbe/streamjs  2015-01-01T15:00:03Z   \n",
       "3  hermanwahyudi       hermanwahyudi/selenium  2015-01-01T15:00:03Z   \n",
       "4          jdilt        jdilt/jdilt.github.io  2015-01-01T15:00:03Z   \n",
       "\n",
       "                                             message               author  \n",
       "0                   Fix main header height on mobile                 rspt  \n",
       "1  #20 게시글 및 댓글 삭제 시 새로고침이 되는 문제 해결\\n\\n원래 의도는 새로고...           Eunsoo Lee  \n",
       "2     Add comparator support for min, max operations  Benjamin Winterberg  \n",
       "3                                   Update README.md               Herman  \n",
       "4                   refine index page and about page                jdilt  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_parquet(\n",
    "    \"test.parq\",\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that's looking good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to the Cloud\n",
    "\n",
    "Now that we have figured out our flow locally, let's build a workflow that will collect the data for a full year (~75GB uncompressed), process it, and save it to cloud object storage.\n",
    "\n",
    "In this section you will:\n",
    "1. Create a list of filenames to extract\n",
    "2. Spin up a Coiled cluster\n",
    "3. Execute the ETL pipeline on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get a list of dates and filenames\n",
    "\n",
    "In the first section, we downloaded a testing file from the internet to our local computer and then wrapped a Dask Bag around it. Now we're going to need to create a Dask Bag around a list of files on the internet. \n",
    "\n",
    "To do that, let's create a list of filenames of all dates in the last year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://data.gharchive.org/2015-01-01-1.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-01-11.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-01-21.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-02-8.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-02-18.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-03-5.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-03-15.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-04-2.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-04-12.json.gz',\n",
       " 'https://data.gharchive.org/2015-01-04-22.json.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of dates of the last year, turn this list into a list of filenames like what is above\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime.strptime(\"01-01-2015\", \"%d-%m-%Y\")\n",
    "end = datetime.datetime.strptime(\"31-12-2015\", \"%d-%m-%Y\")\n",
    "date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "prefix = \"https://data.gharchive.org/\"\n",
    "filenames = []\n",
    "for date in date_generated:\n",
    "    for hour in range(1,24):\n",
    "        filenames.append(prefix + date.strftime(\"%Y-%m-%d\") + '-' + str(hour) + '.json.gz')\n",
    "\n",
    "# Check filenames look ok\n",
    "filenames[:100:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can also create filenames using nested comprehensions\n",
    "# import itertools\n",
    "\n",
    "# filenames_2 = [[prefix + date.strftime(\"%Y-%m-%d\") + '-' + str(hour) + '.json.gz' for hour in range(1,24)] for date in date_generated]\n",
    "# filenames_flat = list(itertools.chain(*filenames_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Dask Cluster on the Cloud\n",
    "\n",
    "Now we launch a Dask cluster in the cloud that can run our ETL pipeline on the entire dataset, i.e. 1 year of Github archive data.  \n",
    "\n",
    "You'll need to make a software environment with the correct libraries so that the workers in your cluster are able to execute our computations. Let's do that first.\n",
    "\n",
    "> *You will need a Free Coiled account for this section. Follow the [Getting Started](https://docs.coiled.io/user_guide/getting_started.html) guide in our docs to create one using just your Github credentials.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# create Coiled software environment\n",
    "coiled.create_software_environment(\n",
    "    name=\"github-parquet\",\n",
    "    conda=[\"dask\", \"pyarrow\", \"s3fs\", \"ujson\", \"requests\", \"lz4\", \"fastparquet\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create Coiled software environments using Docker images, environment.yml (conda) or requirements.txt (pip) files. For more information, check out the [Coiled Docs](https://docs.coiled.io/user_guide/software_environment_creation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your 'blog-notebooks' and 'coiled-examples' accounts are using the ECS backend.\n",
      "After September 16th, accounts using the ECS backend will be migrated to the default AWS VM backend. For more information, refer to the backend documentation and the FAQ:\n",
      "\n",
      "https://docs.coiled.io/user_guide/backends\n",
      "https://docs.coiled.io/user_guide/faq.html#backends\n",
      "Found software environment build\n",
      "Created FW rules: coiled-dask-rrpelgr71-42865-firewall\n",
      "Created scheduler VM: coiled-dask-rrpelgr71-42865-scheduler (type: t3a.medium, ip: ['35.153.126.12'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spin up a Coiled cluster\n",
    "cluster = coiled.Cluster(\n",
    "    name=\"github-parquet\", #name your cluster for future reference\n",
    "    software=\"coiled-examples/github-parquet\", #specify the software environment\n",
    "    n_workers=10, #let's start with 10 workers\n",
    "    shutdown_on_close=False, #this keeps the cluster running if your Python session closes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rpelgrim/mambaforge/envs/etl/lib/python3.9/site-packages/distributed/client.py:1100: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+-------------+---------------+----------------+----------------+\n",
      "| Package     | client        | scheduler      | workers        |\n",
      "+-------------+---------------+----------------+----------------+\n",
      "| dask        | 2021.09.0     | 2021.08.0      | 2021.08.0      |\n",
      "| distributed | 2021.09.0     | 2021.08.0      | 2021.08.0      |\n",
      "| numpy       | 1.21.1        | 1.20.3         | 1.20.3         |\n",
      "| python      | 3.9.6.final.0 | 3.8.11.final.0 | 3.8.11.final.0 |\n",
      "+-------------+---------------+----------------+----------------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-adb7b2d8-0fb7-11ec-bd84-1e008a1e9c26</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> coiled.Cluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://35.153.126.12:8787\" target=\"_blank\">http://35.153.126.12:8787</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">Cluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">github-parquet</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://35.153.126.12:8787\" target=\"_blank\">http://35.153.126.12:8787</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 3\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 6\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 22.69 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-d257c952-a73e-4fb3-bbc0-fb324832305b</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://10.4.1.210:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 3\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.4.1.210:8787/status\" target=\"_blank\">http://10.4.1.210:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 6\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 22.69 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: coiled-rrpelgr71-42865-worker-4f73210130</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.4.31.164:36937\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.4.31.164:44561/status\" target=\"_blank\">http://10.4.31.164:44561/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.56 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.4.31.164:40313\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /dask-worker-space/worker-u5jae8od\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: coiled-rrpelgr71-42865-worker-5adbd5f715</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.4.22.60:34565\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.4.22.60:34047/status\" target=\"_blank\">http://10.4.22.60:34047/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.56 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.4.22.60:45071\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /dask-worker-space/worker-j2m21ix3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: coiled-rrpelgr71-42865-worker-b37daae2cc</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.4.18.165:43743\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.4.18.165:39525/status\" target=\"_blank\">http://10.4.18.165:39525/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.56 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.4.18.165:43917\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /dask-worker-space/worker-8je6p2qw\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.4.1.210:8786' processes=3 threads=6, memory=22.69 GiB>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect Dask to your Coiled cluster\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transform and Load data to Cloud Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moment we've all been waiting for! Your cluster is up, so you're all set to run the ETL pipeline we built above on the entire dataset. Note that this requires just 2 subtle changes:\n",
    "1. pass the entire list **filenames** to `db.read_text` \n",
    "2. point `df.to_parquet` to write to your s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# read in json data\n",
    "records = db.read_text(filenames).map(ujson.loads)\n",
    "\n",
    "# filter out only PushEvents\n",
    "push = records.filter(lambda record: record[\"type\"] == \"PushEvent\")\n",
    "\n",
    "# process into single commit entries\n",
    "processed = push.map(process)\n",
    "\n",
    "# flatten and cast to dataframe\n",
    "df = processed.flatten().to_dataframe()\n",
    "\n",
    "# write to parquet\n",
    "df.to_parquet(\n",
    "    's3://coiled-datasets/etl/test.parq',\n",
    "    engine='pyarrow',\n",
    "    compression='snappy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, that works. But it took quite some time. \n",
    "\n",
    "Let's scale our cluster up to see if we can get better performance. We'll use the `cluster.scale()` command as well as a call to `client.wait_for_workers` which will block activity until all of the workers are online. This way we can be sure that we're throwing all the muscle we have at our computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double n_workers\n",
    "cluster.scale(20)\n",
    "\n",
    "# this blocks activity until the specified number of workers have joined the cluster\n",
    "client.wait_for_workers(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# re-run etl pipeline\n",
    "records = db.read_text(filenames).map(ujson.loads)\n",
    "push = records.filter(lambda record: record[\"type\"] == \"PushEvent\")\n",
    "processed = push.map(process)\n",
    "df = processed.flatten().to_dataframe()\n",
    "df.to_parquet(\n",
    "    's3://coiled-datasets/etl/test.parq',\n",
    "    engine='pyarrow',\n",
    "    compression='snappy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than 10 minutes to process 75GB of data, great job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Let's Recap\n",
    "\n",
    "In this notebook we performed a common ETL workflow: converting raw JSON data into a flattened DataFrame and storing in the efficient Parquet file format on a cloud object store. \n",
    "\n",
    "We performed this first on a single test file locally and then scaled this out to run on the cloud using Dask clusters on Coiled in order to process the entire 75GB dataset for the year 2015.\n",
    "\n",
    "Main takeaways:\n",
    "- Coiled allows you to scale common ETL workflows to larger-than-memory datasets.\n",
    "- Only scale to the cloud if and when you need to. Cloud computing comes with its own set of challenges and overhead. So be strategic about deciding if and when to import Coiled and spin up a cluster.\n",
    "- Scale up your cluster for increased performance. We cut the runtime of the ETL function in half by scaling our cluster from 10 to 20 workers.\n",
    "\n",
    "If you have any questions or suggestions for future material, feel free to drop us a line at support@coiled.io or in our [Coiled Community Slack channel](https://join.slack.com/t/coiled-users/shared_invite/zt-hx1fnr7k-In~Q8ui3XkQfvQon0yN5WQ). We'd love to hear from you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-arm64",
   "language": "python",
   "name": "etl-arm64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
